{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# Category-Level TabPFN Forecasting\n",
    "\n",
    "Generate 2026 forecasts for each retail category using TabPFN with regime dummies only.\n",
    "\n",
    "**Three forecast scenarios**:\n",
    "- **Scenario A (Reversion)**: Pre-COVID dynamics continue (`d_cov=0, d_post=0`)\n",
    "- **Scenario B (COVID Persistence)**: COVID dynamics persist (`d_cov=1, d_post=0`)\n",
    "- **Scenario C (Post-COVID Baseline)**: Post-COVID dynamics persist (`d_cov=1, d_post=1`)\n",
    "\n",
    "**Features**: Regime dummies (`d_cov`, `d_post`) + Calendar features (`month`, `quarter`)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-1",
   "metadata": {},
   "source": [
    "## 0. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cell-2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from autogluon.timeseries import TimeSeriesDataFrame\n",
    "from tabpfn_time_series import TabPFNTimeSeriesPredictor, TabPFNMode\n",
    "from sktime.performance_metrics.forecasting import mean_absolute_error, mean_absolute_scaled_error\n",
    "from sktime.performance_metrics.forecasting.probabilistic import PinballLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cell-3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chart style settings\n",
    "import matplotlib.style as style\n",
    "style.use({\n",
    "    'font.family': 'Monospace',\n",
    "    'font.size': 10,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cell-4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data folders\n",
    "processed_data_dir = Path.cwd().parent / \"data\" / \"processed\"\n",
    "output_figures_dir = Path.cwd().parent / \"outputs\" / \"figures\"\n",
    "output_figures_dir.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cell-5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "HORIZON = 12  # Forecast horizon for evaluation\n",
    "FORECAST_END = pd.Timestamp('2026-12-31')  # Forecast to end of 2026"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-6",
   "metadata": {},
   "source": [
    "### TabPFN Client Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cell-7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… TabPFN client initialized\n"
     ]
    }
   ],
   "source": [
    "import tabpfn_client\n",
    "import dotenv\n",
    "import os\n",
    "\n",
    "# Load API key from .env\n",
    "if os.getenv(\"PRIORLABS_API_KEY\") is None:\n",
    "    raise ValueError(\"Please set the PRIORLABS_API_KEY in the .env file\")\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "token = dotenv.get_key(dotenv.find_dotenv(), \"PRIORLABS_API_KEY\")\n",
    "tabpfn_client.set_access_token(token)\n",
    "\n",
    "print(\"âœ… TabPFN client initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-8",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cell-9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 10 columns\n",
      "Time range: 2015-01-31 00:00:00 to 2025-07-31 00:00:00\n",
      "Total observations: 127\n",
      "\n",
      "Columns: ['all_retail_ex_fuel', 'food_stores', 'non_food_total', 'non_specialised', 'clothing_footwear', 'household_goods', 'other_stores', 'non_store_retail', 'd_cov', 'd_post']\n"
     ]
    }
   ],
   "source": [
    "# Load category data with regime dummies\n",
    "df_categories = pd.read_pickle(processed_data_dir / \"category_data_with_regimes.pkl\")\n",
    "\n",
    "# Load regime analysis results\n",
    "with open(processed_data_dir / \"category_regime_analysis.pkl\", 'rb') as f:\n",
    "    regime_results = pickle.load(f)\n",
    "\n",
    "print(f\"Loaded {len(df_categories.columns)} columns\")\n",
    "print(f\"Time range: {df_categories.index.min()} to {df_categories.index.max()}\")\n",
    "print(f\"Total observations: {len(df_categories)}\")\n",
    "print(f\"\\nColumns: {df_categories.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cell-10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Will forecast 6 categories\n"
     ]
    }
   ],
   "source": [
    "# Define categories to forecast (exclude aggregates)\n",
    "CATEGORIES = [\n",
    "    'food_stores',\n",
    "    'clothing_footwear',\n",
    "    'household_goods',\n",
    "    'non_specialised',\n",
    "    'other_stores',\n",
    "    'non_store_retail'\n",
    "]\n",
    "\n",
    "print(f\"Will forecast {len(CATEGORIES)} categories\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-11",
   "metadata": {},
   "source": [
    "## 1. Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cell-12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_category_tsdf(df, category, train_end_date):\n",
    "    \"\"\"\n",
    "    Prepare TimeSeriesDataFrame for a category with regime dummies and calendar features.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        Category data with regime dummies (d_cov, d_post)\n",
    "    category : str\n",
    "        Category column name\n",
    "    train_end_date : pd.Timestamp\n",
    "        Last date to include in training data\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    train_tsdf : TimeSeriesDataFrame\n",
    "        Training data\n",
    "    test_tsdf_ground_truth : TimeSeriesDataFrame\n",
    "        Test data with ground truth (for evaluation)\n",
    "    \"\"\"\n",
    "    # Filter to training period\n",
    "    df_train = df[df.index <= train_end_date].copy()\n",
    "\n",
    "    # Prepare dataframe for TimeSeriesDataFrame\n",
    "    df_prep = df_train.reset_index()\n",
    "    # Index is named 'date' from category data, need to rename to 'timestamp'\n",
    "    df_prep = df_prep.rename(columns={category: 'target'})\n",
    "    if df_prep.index.name == 'date':\n",
    "        df_prep = df_prep.reset_index()\n",
    "    if 'date' in df_prep.columns:\n",
    "        df_prep = df_prep.rename(columns={'date': 'timestamp'})\n",
    "    df_prep['item_id'] = category\n",
    "\n",
    "    # Add calendar features\n",
    "    df_prep['month'] = df_prep['timestamp'].dt.month\n",
    "    df_prep['quarter'] = df_prep['timestamp'].dt.quarter\n",
    "\n",
    "    # Select columns: target, regime dummies, calendar\n",
    "    cols = ['item_id', 'timestamp', 'target', 'd_cov', 'd_post', 'month', 'quarter']\n",
    "    df_prep = df_prep[cols]\n",
    "\n",
    "    # Create TimeSeriesDataFrame\n",
    "    train_tsdf = TimeSeriesDataFrame.from_data_frame(\n",
    "        df_prep,\n",
    "        id_column='item_id',\n",
    "        timestamp_column='timestamp',\n",
    "        static_features_df=None\n",
    "    )\n",
    "\n",
    "    # Create ground truth test set (for evaluation)\n",
    "    df_test = df[df.index > train_end_date].copy()\n",
    "    df_test_prep = df_test.reset_index()\n",
    "    df_test_prep = df_test_prep.rename(columns={category: 'target'})\n",
    "    if df_test_prep.index.name == 'date':\n",
    "        df_test_prep = df_test_prep.reset_index()\n",
    "    if 'date' in df_test_prep.columns:\n",
    "        df_test_prep = df_test_prep.rename(columns={'date': 'timestamp'})\n",
    "    df_test_prep['item_id'] = category\n",
    "    df_test_prep['month'] = df_test_prep['timestamp'].dt.month\n",
    "    df_test_prep['quarter'] = df_test_prep['timestamp'].dt.quarter\n",
    "    df_test_prep = df_test_prep[cols]\n",
    "\n",
    "    test_tsdf_ground_truth = TimeSeriesDataFrame.from_data_frame(\n",
    "        df_test_prep,\n",
    "        id_column='item_id',\n",
    "        timestamp_column='timestamp',\n",
    "        static_features_df=None\n",
    "    )\n",
    "\n",
    "    return train_tsdf, test_tsdf_ground_truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cell-13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_scenario_test_tsdf(category, test_dates, scenario='C'):\n",
    "    \"\"\"\n",
    "    Create test TimeSeriesDataFrame with scenario-specific regime dummies.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    category : str\n",
    "        Category name\n",
    "    test_dates : pd.DatetimeIndex\n",
    "        Forecast dates\n",
    "    scenario : str, {'A', 'B', 'C'}\n",
    "        Scenario type:\n",
    "        - 'A': Reversion (d_cov=0, d_post=0)\n",
    "        - 'B': COVID Persistence (d_cov=1, d_post=0)\n",
    "        - 'C': Post-COVID Baseline (d_cov=1, d_post=1)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    test_tsdf : TimeSeriesDataFrame\n",
    "        Test data with NaN target and scenario-specific regime dummies\n",
    "    \"\"\"\n",
    "    # Define regime dummy values per scenario\n",
    "    scenario_regimes = {\n",
    "        'A': {'d_cov': 0, 'd_post': 0},  # Pre-COVID\n",
    "        'B': {'d_cov': 1, 'd_post': 0},  # COVID\n",
    "        'C': {'d_cov': 1, 'd_post': 1}   # Post-COVID\n",
    "    }\n",
    "\n",
    "    regimes = scenario_regimes[scenario]\n",
    "\n",
    "    # Create test dataframe\n",
    "    test_df = pd.DataFrame({\n",
    "        'timestamp': test_dates,\n",
    "        'item_id': category,\n",
    "        'target': np.nan,\n",
    "        'd_cov': regimes['d_cov'],\n",
    "        'd_post': regimes['d_post'],\n",
    "        'month': test_dates.month,\n",
    "        'quarter': test_dates.quarter\n",
    "    })\n",
    "\n",
    "    # Create TimeSeriesDataFrame\n",
    "    test_tsdf = TimeSeriesDataFrame.from_data_frame(\n",
    "        test_df,\n",
    "        id_column='item_id',\n",
    "        timestamp_column='timestamp',\n",
    "        static_features_df=None\n",
    "    )\n",
    "\n",
    "    return test_tsdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cell-14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_category_forecast(pred, train_tsdf, test_tsdf_ground_truth, category, horizon=12):\n",
    "    \"\"\"\n",
    "    Evaluate TabPFN forecast for a category.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    pred : pd.DataFrame\n",
    "        TabPFN predictions (MultiIndex with quantiles)\n",
    "    train_tsdf : TimeSeriesDataFrame\n",
    "        Training data\n",
    "    test_tsdf_ground_truth : TimeSeriesDataFrame\n",
    "        Test data with ground truth\n",
    "    category : str\n",
    "        Category name\n",
    "    horizon : int\n",
    "        Forecast horizon for evaluation\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict : Metrics (MAE, MASE, pinball losses, coverage, interval width)\n",
    "    \"\"\"\n",
    "    # Extract predictions\n",
    "    pred_slice = pred.loc[category]\n",
    "\n",
    "    # Extract ground truth (last horizon months)\n",
    "    y_true = (\n",
    "        test_tsdf_ground_truth\n",
    "        .groupby('item_id')\n",
    "        .tail(horizon)\n",
    "        .loc[category]['target']\n",
    "    )\n",
    "\n",
    "    # Extract quantiles\n",
    "    q_low = pred_slice[0.1]\n",
    "    q_med = pred_slice[0.5]\n",
    "    q_high = pred_slice[0.9]\n",
    "\n",
    "    # Align indices\n",
    "    y_true = y_true.reindex(q_med.index)\n",
    "\n",
    "    # Point metrics\n",
    "    mae = float(mean_absolute_error(y_true, q_med))\n",
    "\n",
    "    # MASE\n",
    "    y_train = train_tsdf.loc[category]['target']\n",
    "    mase = float(mean_absolute_scaled_error(y_true, q_med, y_train=y_train, sp=12))\n",
    "\n",
    "    # Probabilistic metrics\n",
    "    pinball = PinballLoss()\n",
    "\n",
    "    y_pred_low = pd.DataFrame(\n",
    "        q_low.values,\n",
    "        index=q_low.index,\n",
    "        columns=pd.MultiIndex.from_tuples([('target', 0.1)], names=['variable', 'alpha'])\n",
    "    )\n",
    "\n",
    "    y_pred_high = pd.DataFrame(\n",
    "        q_high.values,\n",
    "        index=q_high.index,\n",
    "        columns=pd.MultiIndex.from_tuples([('target', 0.9)], names=['variable', 'alpha'])\n",
    "    )\n",
    "\n",
    "    pin_low = float(pinball(y_true, y_pred_low))\n",
    "    pin_high = float(pinball(y_true, y_pred_high))\n",
    "\n",
    "    # Coverage and interval width\n",
    "    coverage_80 = float(((y_true >= q_low) & (y_true <= q_high)).mean())\n",
    "    interval_width = float((q_high - q_low).mean())\n",
    "\n",
    "    return {\n",
    "        'mae': mae,\n",
    "        'mase': mase,\n",
    "        'pinball_0.1': pin_low,\n",
    "        'pinball_0.9': pin_high,\n",
    "        'coverage_80': coverage_80,\n",
    "        'mean_interval_width': interval_width\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cell-15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_category_forecast(pred, train_tsdf, test_tsdf_ground_truth, category, scenario, save_path=None):\n",
    "    \"\"\"\n",
    "    Plot category forecast with confidence intervals.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    pred : pd.DataFrame\n",
    "        TabPFN predictions\n",
    "    train_tsdf : TimeSeriesDataFrame\n",
    "        Training data\n",
    "    test_tsdf_ground_truth : TimeSeriesDataFrame\n",
    "        Test data with ground truth\n",
    "    category : str\n",
    "        Category name\n",
    "    scenario : str\n",
    "        Scenario label\n",
    "    save_path : str, optional\n",
    "        Path to save figure\n",
    "    \"\"\"\n",
    "    # Prepare data\n",
    "    train_df = (\n",
    "        train_tsdf.loc[category]\n",
    "        .reset_index()\n",
    "        .assign(series='train')\n",
    "        .rename(columns={'target': 'value'})\n",
    "    )\n",
    "\n",
    "    actual_df = (\n",
    "        test_tsdf_ground_truth.loc[category]\n",
    "        .reset_index()\n",
    "        .assign(series='actual')\n",
    "        .rename(columns={'target': 'value'})\n",
    "    )\n",
    "\n",
    "    med_df = (\n",
    "        pred.loc[category, 0.5]\n",
    "        .to_frame('value')\n",
    "        .reset_index()\n",
    "        .assign(series='forecast')\n",
    "    )\n",
    "\n",
    "    lo_df = (\n",
    "        pred.loc[category, 0.1]\n",
    "        .to_frame('value')\n",
    "        .reset_index()\n",
    "        .assign(series='lower80')\n",
    "    )\n",
    "\n",
    "    hi_df = (\n",
    "        pred.loc[category, 0.9]\n",
    "        .to_frame('value')\n",
    "        .reset_index()\n",
    "        .assign(series='upper80')\n",
    "    )\n",
    "\n",
    "    plot_df = pd.concat([train_df, actual_df, med_df, lo_df, hi_df], ignore_index=True)\n",
    "\n",
    "    # Plot\n",
    "    fig, ax = plt.subplots(figsize=(16, 5), dpi=300)\n",
    "\n",
    "    sns.lineplot(data=plot_df.query(\"series == 'train'\"), x='timestamp', y='value',\n",
    "                 linewidth=1.5, color='grey', label='train', ax=ax)\n",
    "    sns.lineplot(data=plot_df.query(\"series == 'actual'\"), x='timestamp', y='value',\n",
    "                 linewidth=1.5, color='steelblue', label='actual', ax=ax)\n",
    "    sns.lineplot(data=plot_df.query(\"series == 'forecast'\"), x='timestamp', y='value',\n",
    "                 linewidth=1.5, color='red', label='forecast (median)', ax=ax)\n",
    "\n",
    "    lower = plot_df.query(\"series == 'lower80'\").set_index('timestamp')['value']\n",
    "    upper = plot_df.query(\"series == 'upper80'\").set_index('timestamp')['value']\n",
    "    ax.fill_between(lower.index, lower, upper, color='red', alpha=0.15, label='80% band')\n",
    "\n",
    "    # Formatting\n",
    "    time_range = pd.date_range(start=plot_df['timestamp'].min(), end=plot_df['timestamp'].max(), freq='YS')\n",
    "    ax.set_xticks(time_range)\n",
    "    ax.set_xticklabels([t.year for t in time_range])\n",
    "\n",
    "    for tick in ax.get_xticks():\n",
    "        ax.axvline(x=tick, color='gray', linestyle='--', linewidth=0.5, alpha=0.5)\n",
    "\n",
    "    ax.legend(loc='upper left', fontsize=10)\n",
    "    ax.set_xlabel('')\n",
    "    ax.set_ylabel('Internet Sales as % of Category Total')\n",
    "    ax.grid(axis='y', linestyle='--', alpha=0.5)\n",
    "    ax.set_title(f'{category.replace(\"_\", \" \").title()}: Scenario {scenario}', loc='left', fontsize=12)\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    if save_path:\n",
    "        plt.savefig(save_path, bbox_inches='tight', dpi=300)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-16",
   "metadata": {},
   "source": [
    "## 2. Test Helper Functions on One Category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cell-17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category: food_stores\n",
      "Train shape: (114, 5)\n",
      "Test ground truth shape: (13, 5)\n",
      "\n",
      "Train date range: 2015-01-31 00:00:00 to 2024-06-30 00:00:00\n",
      "Test date range: 2024-07-31 00:00:00 to 2025-07-31 00:00:00\n"
     ]
    }
   ],
   "source": [
    "# Test on food_stores category\n",
    "test_category = 'food_stores'\n",
    "\n",
    "# Split: train on data up to 2024-06-30, test on last 12 months\n",
    "train_end = pd.Timestamp('2024-06-30')\n",
    "\n",
    "# Prepare training data\n",
    "train_tsdf, test_tsdf_ground_truth = prepare_category_tsdf(df_categories, test_category, train_end)\n",
    "\n",
    "print(f\"Category: {test_category}\")\n",
    "print(f\"Train shape: {train_tsdf.shape}\")\n",
    "print(f\"Test ground truth shape: {test_tsdf_ground_truth.shape}\")\n",
    "print(f\"\\nTrain date range: {train_tsdf.index.get_level_values('timestamp').min()} to {train_tsdf.index.get_level_values('timestamp').max()}\")\n",
    "print(f\"Test date range: {test_tsdf_ground_truth.index.get_level_values('timestamp').min()} to {test_tsdf_ground_truth.index.get_level_values('timestamp').max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cell-18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set for Scenario C:\n",
      "Shape: (13, 5)\n",
      "\n",
      "First 3 rows:\n",
      "            target  d_cov  d_post  month  quarter\n",
      "timestamp                                        \n",
      "2024-07-31     NaN      1       1      7        3\n",
      "2024-08-31     NaN      1       1      8        3\n",
      "2024-09-30     NaN      1       1      9        3\n"
     ]
    }
   ],
   "source": [
    "# Create test set for Scenario C (baseline: post-COVID continues)\n",
    "test_dates = test_tsdf_ground_truth.index.get_level_values('timestamp').unique()\n",
    "test_tsdf = create_scenario_test_tsdf(test_category, test_dates, scenario='C')\n",
    "\n",
    "print(f\"Test set for Scenario C:\")\n",
    "print(f\"Shape: {test_tsdf.shape}\")\n",
    "print(f\"\\nFirst 3 rows:\")\n",
    "print(test_tsdf.loc[test_category].head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-19",
   "metadata": {},
   "source": [
    "## 3. Run TabPFN Forecast: Scenario C (Baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cell-20",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "TabPFNRegressor.__init__() got an unexpected keyword argument 'model'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31m_RemoteTraceback\u001b[39m                          Traceback (most recent call last)",
      "\u001b[31m_RemoteTraceback\u001b[39m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/home/mikhailarutyunov/projects/time-series-methods/time-series-methods/.venv/lib/python3.12/site-packages/joblib/externals/loky/process_executor.py\", line 490, in _process_worker\n    r = call_item()\n        ^^^^^^^^^^^\n  File \"/home/mikhailarutyunov/projects/time-series-methods/time-series-methods/.venv/lib/python3.12/site-packages/joblib/externals/loky/process_executor.py\", line 291, in __call__\n    return self.fn(*self.args, **self.kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/mikhailarutyunov/projects/time-series-methods/time-series-methods/.venv/lib/python3.12/site-packages/joblib/parallel.py\", line 607, in __call__\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n            ^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/mikhailarutyunov/projects/time-series-methods/time-series-methods/.venv/lib/python3.12/site-packages/tabpfn_time_series/tabpfn_worker.py\", line 71, in _prediction_routine\n    result = self._worker_specific_prediction_routine(\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/mikhailarutyunov/projects/time-series-methods/time-series-methods/.venv/lib/python3.12/site-packages/tabpfn_time_series/tabpfn_worker.py\", line 153, in _worker_specific_prediction_routine\n    tabpfn = TabPFNRegressor(**self.tabpfn_config)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nTypeError: TabPFNRegressor.__init__() got an unexpected keyword argument 'model'\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m predictor = TabPFNTimeSeriesPredictor(tabpfn_mode=TabPFNMode.CLIENT)\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Predict\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m pred_C = \u001b[43mpredictor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_tsdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_tsdf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mPrediction shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpred_C.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m      8\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mFirst 3 predictions (median):\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/time-series-methods/time-series-methods/.venv/lib/python3.12/site-packages/tabpfn_time_series/predictor.py:47\u001b[39m, in \u001b[36mTabPFNTimeSeriesPredictor.predict\u001b[39m\u001b[34m(self, train_tsdf, test_tsdf, quantile_config)\u001b[39m\n\u001b[32m     39\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     40\u001b[39m \u001b[33;03mPredict on each time series individually (local forecasting).\u001b[39;00m\n\u001b[32m     41\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     43\u001b[39m logger.info(\n\u001b[32m     44\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mPredicting \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(train_tsdf.item_ids)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m time series with config\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.tabpfn_worker.tabpfn_config\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m     45\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m47\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtabpfn_worker\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_tsdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_tsdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquantile_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/time-series-methods/time-series-methods/.venv/lib/python3.12/site-packages/tabpfn_time_series/tabpfn_worker.py:142\u001b[39m, in \u001b[36mTabPFNClient.predict\u001b[39m\u001b[34m(self, train_tsdf, test_tsdf, quantile_config)\u001b[39m\n\u001b[32m    136\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mset\u001b[39m(quantile_config).issubset(\u001b[38;5;28mset\u001b[39m(TABPFN_DEFAULT_QUANTILE_CONFIG)):\n\u001b[32m    137\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[32m    138\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTabPFNClient currently only supports \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mTABPFN_DEFAULT_QUANTILE_CONFIG\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m for quantile prediction,\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    139\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquantile_config\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    140\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m142\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_tsdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_tsdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquantile_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/time-series-methods/time-series-methods/.venv/lib/python3.12/site-packages/tabpfn_time_series/tabpfn_worker.py:31\u001b[39m, in \u001b[36mTabPFNWorker.predict\u001b[39m\u001b[34m(self, train_tsdf, test_tsdf, quantile_config)\u001b[39m\n\u001b[32m     25\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpredict\u001b[39m(\n\u001b[32m     26\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m     27\u001b[39m     train_tsdf: TimeSeriesDataFrame,\n\u001b[32m     28\u001b[39m     test_tsdf: TimeSeriesDataFrame,\n\u001b[32m     29\u001b[39m     quantile_config: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mfloat\u001b[39m],\n\u001b[32m     30\u001b[39m ):\n\u001b[32m---> \u001b[39m\u001b[32m31\u001b[39m     predictions = \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     32\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnum_workers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     33\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbackend\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mloky\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     34\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     35\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_prediction_routine\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     36\u001b[39m \u001b[43m            \u001b[49m\u001b[43mitem_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     37\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtrain_tsdf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mitem_id\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     38\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtest_tsdf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mitem_id\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     39\u001b[39m \u001b[43m            \u001b[49m\u001b[43mquantile_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     40\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     41\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mitem_id\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain_tsdf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitem_ids\u001b[49m\n\u001b[32m     42\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     44\u001b[39m     predictions = pd.concat(predictions)\n\u001b[32m     46\u001b[39m     \u001b[38;5;66;03m# Sort predictions according to original item_ids order (important for MASE and WQL calculation)\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/time-series-methods/time-series-methods/.venv/lib/python3.12/site-packages/joblib/parallel.py:2072\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   2066\u001b[39m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[32m   2067\u001b[39m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[32m   2068\u001b[39m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[32m   2069\u001b[39m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[32m   2070\u001b[39m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[32m-> \u001b[39m\u001b[32m2072\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/time-series-methods/time-series-methods/.venv/lib/python3.12/site-packages/joblib/parallel.py:1682\u001b[39m, in \u001b[36mParallel._get_outputs\u001b[39m\u001b[34m(self, iterator, pre_dispatch)\u001b[39m\n\u001b[32m   1679\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[32m   1681\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backend.retrieval_context():\n\u001b[32m-> \u001b[39m\u001b[32m1682\u001b[39m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m._retrieve()\n\u001b[32m   1684\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[32m   1685\u001b[39m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[32m   1686\u001b[39m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[32m   1687\u001b[39m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[32m   1688\u001b[39m     \u001b[38;5;28mself\u001b[39m._exception = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/time-series-methods/time-series-methods/.venv/lib/python3.12/site-packages/joblib/parallel.py:1784\u001b[39m, in \u001b[36mParallel._retrieve\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1778\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m._wait_retrieval():\n\u001b[32m   1779\u001b[39m     \u001b[38;5;66;03m# If the callback thread of a worker has signaled that its task\u001b[39;00m\n\u001b[32m   1780\u001b[39m     \u001b[38;5;66;03m# triggered an exception, or if the retrieval loop has raised an\u001b[39;00m\n\u001b[32m   1781\u001b[39m     \u001b[38;5;66;03m# exception (e.g. `GeneratorExit`), exit the loop and surface the\u001b[39;00m\n\u001b[32m   1782\u001b[39m     \u001b[38;5;66;03m# worker traceback.\u001b[39;00m\n\u001b[32m   1783\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._aborting:\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_raise_error_fast\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1785\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m   1787\u001b[39m     nb_jobs = \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m._jobs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/time-series-methods/time-series-methods/.venv/lib/python3.12/site-packages/joblib/parallel.py:1859\u001b[39m, in \u001b[36mParallel._raise_error_fast\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1855\u001b[39m \u001b[38;5;66;03m# If this error job exists, immediately raise the error by\u001b[39;00m\n\u001b[32m   1856\u001b[39m \u001b[38;5;66;03m# calling get_result. This job might not exists if abort has been\u001b[39;00m\n\u001b[32m   1857\u001b[39m \u001b[38;5;66;03m# called directly or if the generator is gc'ed.\u001b[39;00m\n\u001b[32m   1858\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m error_job \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1859\u001b[39m     \u001b[43merror_job\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_result\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/time-series-methods/time-series-methods/.venv/lib/python3.12/site-packages/joblib/parallel.py:758\u001b[39m, in \u001b[36mBatchCompletionCallBack.get_result\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    752\u001b[39m backend = \u001b[38;5;28mself\u001b[39m.parallel._backend\n\u001b[32m    754\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m backend.supports_retrieve_callback:\n\u001b[32m    755\u001b[39m     \u001b[38;5;66;03m# We assume that the result has already been retrieved by the\u001b[39;00m\n\u001b[32m    756\u001b[39m     \u001b[38;5;66;03m# callback thread, and is stored internally. It's just waiting to\u001b[39;00m\n\u001b[32m    757\u001b[39m     \u001b[38;5;66;03m# be returned.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m758\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_return_or_raise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    760\u001b[39m \u001b[38;5;66;03m# For other backends, the main thread needs to run the retrieval step.\u001b[39;00m\n\u001b[32m    761\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/time-series-methods/time-series-methods/.venv/lib/python3.12/site-packages/joblib/parallel.py:773\u001b[39m, in \u001b[36mBatchCompletionCallBack._return_or_raise\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    771\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    772\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.status == TASK_ERROR:\n\u001b[32m--> \u001b[39m\u001b[32m773\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._result\n\u001b[32m    774\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._result\n\u001b[32m    775\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[31mTypeError\u001b[39m: TabPFNRegressor.__init__() got an unexpected keyword argument 'model'"
     ]
    }
   ],
   "source": [
    "# Initialize TabPFN predictor\n",
    "predictor = TabPFNTimeSeriesPredictor(tabpfn_mode=TabPFNMode.CLIENT)\n",
    "\n",
    "# Predict\n",
    "pred_C = predictor.predict(train_tsdf, test_tsdf)\n",
    "\n",
    "print(f\"Prediction shape: {pred_C.shape}\")\n",
    "print(f\"\\nFirst 3 predictions (median):\")\n",
    "print(pred_C.loc[test_category, 0.5].head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Scenario C\n",
    "metrics_C = evaluate_category_forecast(\n",
    "    pred=pred_C,\n",
    "    train_tsdf=train_tsdf,\n",
    "    test_tsdf_ground_truth=test_tsdf_ground_truth,\n",
    "    category=test_category,\n",
    "    horizon=HORIZON\n",
    ")\n",
    "\n",
    "print(f\"\\n{test_category.replace('_', ' ').title()} - Scenario C Metrics:\")\n",
    "for key, val in metrics_C.items():\n",
    "    print(f\"  {key:20s}: {val:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Scenario C\n",
    "plot_category_forecast(\n",
    "    pred=pred_C,\n",
    "    train_tsdf=train_tsdf,\n",
    "    test_tsdf_ground_truth=test_tsdf_ground_truth,\n",
    "    category=test_category,\n",
    "    scenario='C (Post-COVID Baseline)',\n",
    "    save_path=output_figures_dir / f'{test_category}_scenario_C.png'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-23",
   "metadata": {},
   "source": [
    "## 4. Run All Scenarios for Test Category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Scenario A (Reversion)\n",
    "test_tsdf_A = create_scenario_test_tsdf(test_category, test_dates, scenario='A')\n",
    "pred_A = predictor.predict(train_tsdf, test_tsdf_A)\n",
    "metrics_A = evaluate_category_forecast(pred_A, train_tsdf, test_tsdf_ground_truth, test_category, HORIZON)\n",
    "\n",
    "print(f\"\\n{test_category.replace('_', ' ').title()} - Scenario A Metrics (Reversion):\")\n",
    "for key, val in metrics_A.items():\n",
    "    print(f\"  {key:20s}: {val:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Scenario B (COVID Persistence)\n",
    "test_tsdf_B = create_scenario_test_tsdf(test_category, test_dates, scenario='B')\n",
    "pred_B = predictor.predict(train_tsdf, test_tsdf_B)\n",
    "metrics_B = evaluate_category_forecast(pred_B, train_tsdf, test_tsdf_ground_truth, test_category, HORIZON)\n",
    "\n",
    "print(f\"\\n{test_category.replace('_', ' ').title()} - Scenario B Metrics (COVID Persistence):\")\n",
    "for key, val in metrics_B.items():\n",
    "    print(f\"  {key:20s}: {val:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare scenarios\n",
    "scenario_comparison = pd.DataFrame({\n",
    "    'Scenario A (Reversion)': metrics_A,\n",
    "    'Scenario B (COVID)': metrics_B,\n",
    "    'Scenario C (Post-COVID)': metrics_C\n",
    "}).T\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"SCENARIO COMPARISON: {test_category.replace('_', ' ').title()}\")\n",
    "print(f\"{'='*80}\")\n",
    "print(scenario_comparison.round(4))\n",
    "print(f\"\\nBest scenario by MAE: {scenario_comparison['mae'].idxmin()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-27",
   "metadata": {},
   "source": [
    "## 5. Run All Categories Ã— All Scenarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run forecasts for all categories and scenarios\n",
    "results = {}\n",
    "\n",
    "for category in CATEGORIES:\n",
    "    print(f\"\\n{'='*100}\")\n",
    "    print(f\"Processing: {category.replace('_', ' ').title()}\")\n",
    "    print(f\"{'='*100}\")\n",
    "    \n",
    "    # Prepare data\n",
    "    train_tsdf, test_tsdf_ground_truth = prepare_category_tsdf(df_categories, category, train_end)\n",
    "    test_dates = test_tsdf_ground_truth.index.get_level_values('timestamp').unique()\n",
    "    \n",
    "    category_results = {}\n",
    "    \n",
    "    for scenario in ['A', 'B', 'C']:\n",
    "        print(f\"  Scenario {scenario}...\", end=' ')\n",
    "        \n",
    "        # Create test set\n",
    "        test_tsdf = create_scenario_test_tsdf(category, test_dates, scenario=scenario)\n",
    "        \n",
    "        # Predict\n",
    "        pred = predictor.predict(train_tsdf, test_tsdf)\n",
    "        \n",
    "        # Evaluate\n",
    "        metrics = evaluate_category_forecast(pred, train_tsdf, test_tsdf_ground_truth, category, HORIZON)\n",
    "        \n",
    "        # Store results\n",
    "        category_results[scenario] = {\n",
    "            'pred': pred,\n",
    "            'metrics': metrics\n",
    "        }\n",
    "        \n",
    "        print(f\"MAE: {metrics['mae']:.3f}\")\n",
    "    \n",
    "    # Store category results\n",
    "    results[category] = {\n",
    "        'train_tsdf': train_tsdf,\n",
    "        'test_tsdf_ground_truth': test_tsdf_ground_truth,\n",
    "        'scenarios': category_results\n",
    "    }\n",
    "\n",
    "print(f\"\\nâœ… All forecasts complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-29",
   "metadata": {},
   "source": [
    "## 6. Summary: Best Scenario per Category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create summary table\n",
    "summary_data = []\n",
    "\n",
    "for category in CATEGORIES:\n",
    "    cat_results = results[category]['scenarios']\n",
    "    \n",
    "    mae_A = cat_results['A']['metrics']['mae']\n",
    "    mae_B = cat_results['B']['metrics']['mae']\n",
    "    mae_C = cat_results['C']['metrics']['mae']\n",
    "    \n",
    "    best_scenario = min([('A', mae_A), ('B', mae_B), ('C', mae_C)], key=lambda x: x[1])[0]\n",
    "    \n",
    "    summary_data.append({\n",
    "        'Category': category.replace('_', ' ').title(),\n",
    "        'MAE Scenario A': mae_A,\n",
    "        'MAE Scenario B': mae_B,\n",
    "        'MAE Scenario C': mae_C,\n",
    "        'Best Scenario': best_scenario,\n",
    "        'Best MAE': min(mae_A, mae_B, mae_C)\n",
    "    })\n",
    "\n",
    "summary_df = pd.DataFrame(summary_data)\n",
    "summary_df = summary_df.round(3)\n",
    "\n",
    "print(f\"\\n{'='*100}\")\n",
    "print(f\"SUMMARY: BEST SCENARIO BY CATEGORY (MAE)\")\n",
    "print(f\"{'='*100}\")\n",
    "print(summary_df.to_string(index=False))\n",
    "\n",
    "print(f\"\\nScenario distribution:\")\n",
    "print(summary_df['Best Scenario'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-31",
   "metadata": {},
   "source": [
    "## 7. Visualize: Scenario Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar chart: MAE by scenario and category\n",
    "fig, ax = plt.subplots(figsize=(14, 6), dpi=300)\n",
    "\n",
    "x = np.arange(len(CATEGORIES))\n",
    "width = 0.25\n",
    "\n",
    "mae_A_vals = [results[cat]['scenarios']['A']['metrics']['mae'] for cat in CATEGORIES]\n",
    "mae_B_vals = [results[cat]['scenarios']['B']['metrics']['mae'] for cat in CATEGORIES]\n",
    "mae_C_vals = [results[cat]['scenarios']['C']['metrics']['mae'] for cat in CATEGORIES]\n",
    "\n",
    "ax.bar(x - width, mae_A_vals, width, label='Scenario A (Reversion)', color='green', alpha=0.8)\n",
    "ax.bar(x, mae_B_vals, width, label='Scenario B (COVID)', color='orange', alpha=0.8)\n",
    "ax.bar(x + width, mae_C_vals, width, label='Scenario C (Post-COVID)', color='steelblue', alpha=0.8)\n",
    "\n",
    "ax.set_ylabel('MAE (pp)')\n",
    "ax.set_title('Forecast Accuracy by Scenario and Category', loc='left', fontsize=12)\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels([cat.replace('_', ' ').title() for cat in CATEGORIES], rotation=45, ha='right')\n",
    "ax.legend()\n",
    "ax.grid(axis='y', linestyle='--', alpha=0.5)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(output_figures_dir / 'scenario_comparison_mae.png', bbox_inches='tight', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-33",
   "metadata": {},
   "source": [
    "## 8. Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save forecast results\n",
    "forecast_results = {}\n",
    "\n",
    "for category in CATEGORIES:\n",
    "    cat_results = results[category]\n",
    "    \n",
    "    forecast_results[category] = {\n",
    "        'scenarios': {\n",
    "            'A': cat_results['scenarios']['A']['metrics'],\n",
    "            'B': cat_results['scenarios']['B']['metrics'],\n",
    "            'C': cat_results['scenarios']['C']['metrics']\n",
    "        }\n",
    "    }\n",
    "\n",
    "output_path = processed_data_dir / 'category_forecast_results.pkl'\n",
    "with open(output_path, 'wb') as f:\n",
    "    pickle.dump(forecast_results, f)\n",
    "\n",
    "print(f\"âœ… Forecast results saved to {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save summary table\n",
    "summary_df.to_csv(processed_data_dir / 'category_forecast_summary.csv', index=False)\n",
    "print(f\"âœ… Summary table saved to {processed_data_dir / 'category_forecast_summary.csv'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print completion message\n",
    "print('\\n' + '=' * 100)\n",
    "print('ðŸ“‹ NOTEBOOK 06 COMPLETE')\n",
    "print('=' * 100)\n",
    "print(f'\\nKey findings:')\n",
    "print(f'  - Forecasted {len(CATEGORIES)} categories with 3 scenarios each')\n",
    "print(f'  - Evaluated forecast accuracy on {HORIZON}-month holdout period')\n",
    "print(f'  - Identified best scenario per category based on MAE')\n",
    "print(f'\\nâœ… Ready for aggregation in notebook 07')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "time-series-methods",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
